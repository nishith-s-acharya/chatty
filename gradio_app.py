from dotenv import load_dotenv
load_dotenv(override=True)

import os
import logging
import gradio as gr
import subprocess
import tempfile
import numpy as np
import soundfile as sf
from deep_translator import GoogleTranslator  # ‚úÖ new translator

from brain_of_the_doctor import encode_image, analyze_image_with_query
from voice_of_the_patient import transcribe_with_assemblyai
from voice_of_the_doctor import text_to_speech_with_elevenlabs

# Setup logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# Doctor system prompts (base in English)
base_prompt_with_image = """You have to act as a professional doctor, i know you are not but this is for learning purpose. 
What's in this image?. Do you find anything wrong with it medically? 
If you make a differential, suggest some remedies for them. Donot add any numbers or special characters in 
your response. Your response should be in one long paragraph. Also always answer as if you are answering to a real person.
Donot say 'In the image I see' but say 'With what I see, I think you have ....'
Dont respond as an AI model in markdown, your answer should mimic that of an actual doctor not an AI bot, 
Keep your answer concise (max 2 sentences). No preamble, start your answer right away please"""

base_prompt_voice_only = """You have to act as a professional doctor (for learning purposes). The patient only described their symptoms via speech; no medical image is available. Listen to what they said (transcript is provided) and infer the most likely causes plus concrete suggestions (home care, medications to discuss with a doctor, red-flag symptoms). Avoid bullet points, keep it to one paragraph in natural language, maximum two sentences, and sound like an actual doctor speaking to a patient."""


def process_inputs(audio_input, image_filepath, progress=gr.Progress()):
    try:
        speech_to_text_output = ""
        detected_lang = "en"   # default fallback
        patient_voice_mp3 = None
        doctor_voice_mp3 = None
        doctor_response = ""

        # -------------------------------
        # Step 1: Handle Voice (Mic Input)
        # -------------------------------
        if audio_input is not None:
            logging.info("üé§ Patient voice received from microphone")

            # ‚úÖ Handle tuple (sample_rate, numpy_array) or plain array
            if isinstance(audio_input, tuple):
                sample_rate = audio_input[0]   # first element is sample_rate
                audio_data = audio_input[1]    # second element is numpy array
                logging.info(f"‚úÖ Tuple format detected. sample_rate={sample_rate}, shape={getattr(audio_data, 'shape', None)}")
            else:
                audio_data = audio_input
                sample_rate = 44100  # fallback default
                logging.info("‚úÖ Array format detected. sample_rate=44100")

            # ‚úÖ Ensure audio is always 2D (samples, channels)
            if hasattr(audio_data, "ndim") and audio_data.ndim == 1:
                audio_data = np.expand_dims(audio_data, axis=1)
                logging.info("‚úÖ Expanded mono to 2D array")

            # Save to temporary WAV file
            wav_path = tempfile.NamedTemporaryFile(suffix=".wav", delete=False).name
            sf.write(wav_path, audio_data, sample_rate)
            logging.info(f"Temporary WAV saved: {wav_path}")

            # Convert to MP3 for playback
            patient_voice_mp3 = tempfile.NamedTemporaryFile(suffix=".mp3", delete=False).name
            subprocess.run(
                ["ffmpeg", "-y", "-i", wav_path, "-ar", "44100", "-ac", "2", patient_voice_mp3],
                check=True,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
            )
            logging.info(f"Patient voice converted to MP3: {patient_voice_mp3}")

            # Transcribe
            progress(0.2, desc="‚è≥ Transcribing speech with AssemblyAI...")
            speech_to_text_output, detected_lang = transcribe_with_assemblyai(wav_path)

        else:
            logging.info("‚ö†Ô∏è No patient voice provided.")

        # -------------------------------
        # Step 2: Translate base prompt
        # -------------------------------
        prompt_to_translate = base_prompt_with_image if image_filepath else base_prompt_voice_only
        progress(0.4, desc=f"üåç Preparing doctor instructions in {detected_lang}...")
        try:
            translated_prompt = GoogleTranslator(source="auto", target=detected_lang).translate(prompt_to_translate)
        except Exception as e:
            logging.error(f"Translation failed, using English prompt: {e}")
            translated_prompt = prompt_to_translate

        # -------------------------------
        # Step 3: Doctor reasoning
        # -------------------------------
        progress(0.6, desc="ü§î Doctor is analyzing...")
        query_text = f"{translated_prompt}\n\n"

        if speech_to_text_output:
            query_text += f"The patient spoke in {detected_lang}. Patient said: {speech_to_text_output}.\n"
        else:
            query_text += "No speech was provided.\n"

        encoded_image = None
        if image_filepath:
            encoded_image = encode_image(image_filepath)
            query_text += "A medical image is attached. Use it for your assessment."
        else:
            query_text += "No medical image is available. Offer guidance based solely on the patient's description."

        if image_filepath or speech_to_text_output:
            doctor_response = analyze_image_with_query(
                query=query_text,
                model="gemini-flash-latest",
                encoded_image=encoded_image
            )
        else:
            doctor_response = "‚ö†Ô∏è No input provided (neither speech nor image)."

        # -------------------------------
        # Step 3.5: Match doctor reply language to patient
        # -------------------------------
        should_translate_reply = bool(speech_to_text_output) and detected_lang not in (None, "", "error")
        if doctor_response and should_translate_reply:
            try:
                doctor_response = GoogleTranslator(source="auto", target=detected_lang).translate(doctor_response)
            except Exception as e:
                logging.error(f"Doctor response translation failed, using original text: {e}")

        # -------------------------------
        # Step 4: TTS (Doctor Reply)
        # -------------------------------
        if doctor_response:
            progress(0.8, desc="üó£ Converting doctor‚Äôs reply to speech...")
            doctor_voice_mp3 = text_to_speech_with_elevenlabs(
                input_text=doctor_response,
                output_filepath="doctor_final.mp3",
                lang=detected_lang
            )

        progress(1.0, desc="‚úÖ Done")
        return (
            speech_to_text_output or "No speech provided.",
            detected_lang,
            doctor_response,
            patient_voice_mp3,
            doctor_voice_mp3,
        )

    except Exception as e:
        import traceback
        logging.error(traceback.format_exc())
        return f"Pipeline error: {e}", "error", "error", None, None


# -------------------------------
# Gradio Interface
# -------------------------------
iface = gr.Interface(
    fn=process_inputs,
    inputs=[
        gr.Audio(sources=["microphone"], type="numpy", label="üé§ Patient Voice (Speak here)"),
        gr.Image(type="filepath", label="ü©∫ Upload Medical Image")
    ],
    outputs=[
        gr.Textbox(label="üó£ Speech to Text"),
        gr.Textbox(label="üåç Detected Language"),
        gr.Textbox(label="üë®‚Äç‚öïÔ∏è Doctor's Response"),
        gr.Audio(type="filepath", label="üîä Patient Voice (playback)"),
        gr.Audio(type="filepath", label="üîä Doctor's Reply")
    ],
    title="AI Doctor (Multilingual with AssemblyAI)",
    description="1. Speak about your symptoms in any language.\n2. Upload a medical image.\n3. Click Submit.\nDoctor will reply in your own language."
)

# -------------------------------
# Local vs Railway distinction
# -------------------------------
if os.environ.get("RAILWAY_ENVIRONMENT"):  # üöÄ Railway deployment
    # ‚úÖ Directly expose ASGI app
    app = iface.app
else:  # üíª Local development
    iface.launch(server_name="0.0.0.0", server_port=7860, debug=True)